---
title: "neural nets"
author: "Keerthana"

output: html_document
---
### This file implements Neural Nets to Parkinson's data
```{r}
library(caret)
library(class)
library(ISLR)
# loading training data
data_train <- read.table("train_data.txt",sep=",",row.names=NULL,col.names=c("subject id", "jitter1","jitter2","jitter3","jitter4","jitter5","shimmer1","shimmer2","shimmer3","shimmer4","shimmer5","shimmer6","AC","NTH","HTN","median pitch","mean pitch","sd","min pitch","max pitch","num pulses","Number of periods","Mean period","Standard deviation of period","Fraction of locally unvoiced frames","Number of voice breaks","Degree of voice breaks","UPDRS","class"),fill=FALSE)
train_data=data_train[,1:27]
train_response=data_train[,29]

# loading test data
data_test <- read.table("test_data.txt",sep=",",row.names=NULL,col.names=c("subject id", "jitter1","jitter2","jitter3","jitter4","jitter5","shimmer1","shimmer2","shimmer3","shimmer4","shimmer5","shimmer6","AC","NTH","HTN","median pitch","mean pitch","sd","min pitch","max pitch","num pulses","Number of periods","Mean period","Standard deviation of period","Fraction of locally unvoiced frames","Number of voice breaks","Degree of voice breaks","class"),fill=FALSE)
test_data=data_test[,1:27]
test_response=data_test[,28]

```


```{r}
# standardise the data
train_data_norm=train_data[,2:27]
test_data_norm=test_data[,2:27]
data=rbind(train_data_norm,test_data_norm)
# Uncomment the following line of code to run the modeol for only 14 input features
data=data[,c(2,6,10,12,13,14,17,18,19,20,21,24,25,26)]
response=c(train_response,test_response)
```

### Summarizing the input data using central tendency and dispersion metrics

```{r}

train_mat1=matrix(0,40,52)
train_mat2=matrix(0,40,52)
train_mat3=matrix(0,40,52)
train_response_mat=matrix(0,40,1)
for (i in 0:39){
for (j in 1:26){
l=i*26+1
m=i*26+26
train_mat1[i+1,j]=mean(train_data_norm[l:m,j])
train_mat2[i+1,j]=median(train_data_norm[l:m,j])
train_mat3[i+1,j]=mean(train_data_norm[l:m,j],trim = 0.125)

train_mat1[i+1,j+26]=sd(train_data_norm[l:m,j])
train_mat2[i+1,j+26]=mad(train_data_norm[l:m,j])
train_mat3[i+1,j+26]=IQR(train_data_norm[l:m,j])

}
train_response_mat[i+1]=train_response[i*26+1]
}

test_mat1=matrix(0,28,52)
test_mat2=matrix(0,28,52)
test_mat3=matrix(0,28,52)
test_response_mat=matrix(0,28,1)
for (i in 0:27){
for (j in 1:26){
l=i*6+1
m=i*6+6
test_mat1[i+1,j]=mean(test_data_norm[l:m,j])
test_mat2[i+1,j]=median(test_data_norm[l:m,j])
test_mat3[i+1,j]=mean(test_data_norm[l:m,j],trim = 0.125)

test_mat1[i+1,j+26]=sd(test_data_norm[l:m,j])
test_mat2[i+1,j+26]=mad(test_data_norm[l:m,j])
test_mat3[i+1,j+26]=IQR(test_data_norm[l:m,j])
}
  test_response_mat[i+1]=test_response[i*6+1]
}
train_mat=cbind(train_mat1,train_mat2,train_mat3)
test_mat=cbind(test_mat1,test_mat2,test_mat3)
data_modified1=rbind(train_mat1,test_mat1)
data_modified2=rbind(train_mat2,test_mat2)
data_modified3=rbind(train_mat3,test_mat3)
data_modified=rbind(train_mat,test_mat)
modified_response=c(train_response_mat,test_response_mat)


```

### Apply nnet to the dataset

```{r}
library(nnet)
acc=matrix(0,10,1)
MCC=matrix(0,10,1)
sensi=matrix(0,10,1)
speci=matrix(0,10,1)
for (k in 1:10){
set.seed(k)
Rand_index<-sample(1:1208, 800) 

# Generate training data and testing data
X_train=scale(data[Rand_index,])
X_test=scale(data[-Rand_index,])
y_train=response[Rand_index]
y_test=response[-Rand_index]

# Apply nnet
set.seed(1)
dataFrame<-data.frame(x=X_train,y=class.ind(as.factor(y_train)))
testFrame<-data.frame(x=X_test,y=class.ind(as.factor(y_test)))
NN<-nnet(X_train,class.ind(y_train),size=25,softmax = TRUE)
pred<-predict(NN, X_test, type="class")
table(pred,y_test)
TN=0
TP=0
FN=0
FP=0
for (i in 1:408){
  if(y_test[i]==pred[i])
  {
    if(pred[i]==0)
      TN=TN+1
    else
      TP=TP+1
  }
  else
  {
    if(pred[i]==0)
      FN=FN+1
    else
      FP=FP+1
  }
}
acc[k]=(TP+TN)/408
sensi[k]=TP/(TP+FN)
speci[k]=TN/(TN+FP)
MCC[k]=(TP*TN-FP*FN)/sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))
}
mean(acc)
mean(sensi)
mean(speci)
mean(MCC)
```

### Apply nnet to summarized dataset

```{r}
library(nnet)
for (k in 1:10){
set.seed(k)
Rand_index<-sample(1:68, 40) 

# Generate training and testing dataset
X_train=data_modified2[Rand_index,] 
X_test=data_modified2[-Rand_index,]
y_train=modified_response[Rand_index]
y_test=modified_response[-Rand_index]

# Apply nnet
set.seed(2)
dataFrame<-data.frame(x=X_train,y=class.ind(as.factor(y_train)))
testFrame<-data.frame(x=X_test,y=class.ind(as.factor(y_test)))
NN<-nnet(X_train,class.ind(y_train),size=10,softmax = TRUE)
pred<-predict(NN, X_test, type="class")
TN=0
TP=0
FN=0
FP=0
for (i in 1:28){
  if(y_test[i]==pred[i])
  {
    if(pred[i]==0)
      TN=TN+1
    else
      TP=TP+1
  }
  else
  {
    if(pred[i]==0)
      FN=FN+1
    else
      FP=FP+1
  }
}
acc[k]=(TP+TN)/40
sensi[k]=TP/(TP+FN)
speci[k]=TN/(TN+FP)
MCC[k]=(TP*TN-FP*FN)/sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))
}
acc=mean(acc)
sensi=mean(sensi)
speci=mean(speci)
MCC=mean(MCC)
acc
MCC
sensi
speci
```



